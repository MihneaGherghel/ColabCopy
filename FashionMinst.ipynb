{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MihneaGherghel/FashionMinst/blob/main/FashionMinst.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW7OsblB1Vf-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqgqDNldCoFU"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99TqK1wg1gWO"
      },
      "outputs": [],
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=\n",
        "                                                transforms.Compose([transforms.ToTensor()]))\n",
        "train_size = int(0.8 * len(train_set))\n",
        "val_size = len(train_set) - train_size\n",
        "train_set, val_set = random_split(train_set, [train_size, val_size])\n",
        "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=\n",
        "                                               transforms.Compose([transforms.ToTensor()]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fhRVkmOm1jP1"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=100)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,batch_size=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gMdzGQt1jWY"
      },
      "outputs": [],
      "source": [
        "class FashionCNN(nn.Module):\n",
        "  def __init__(self):\n",
        "      super(FashionCNN, self).__init__()\n",
        "\n",
        "      self.sequential1=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=1, out_channels=128, kernel_size=3, padding=1),\n",
        "        #nn.BatchNorm2d(128),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "      )\n",
        "\n",
        "      self.sequential2=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=128, out_channels=512, kernel_size=3, padding=1),\n",
        "        #nn.BatchNorm2d(512),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "      )\n",
        "\n",
        "      self.sequential3=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=512, out_channels=2048, kernel_size=3, padding=1),\n",
        "        #nn.BatchNorm2d(2048),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "      )\n",
        "\n",
        "      self.sequential4=nn.Sequential(\n",
        "        nn.Conv2d(in_channels=2048, out_channels=8192, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "      )\n",
        "\n",
        "      self.sequential5=nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(8192,1000),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(1000,500),\n",
        "      )\n",
        "      self.out=nn.Linear(500,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = self.sequential1(x)\n",
        "      x = self.sequential2(x)\n",
        "      x = self.sequential3(x)\n",
        "      x = self.sequential4(x)\n",
        "      x= self.sequential5(x)\n",
        "      x=self.out(x)\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxlKsSD15BwS"
      },
      "outputs": [],
      "source": [
        "model = FashionCNN()\n",
        "model.to(device)\n",
        "error = nn.CrossEntropyLoss()\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "num_epochs = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDs9NMnN5Qlm",
        "outputId": "623e0edc-5771-48ef-b2c9-e6aa05e09177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration: 500, Loss: 0.36577510833740234, Accuracy: 86.89166259765625%\n",
            "Iteration: 1000, Loss: 0.31450822949409485, Accuracy: 89.03333282470703%\n",
            "Iteration: 1500, Loss: 0.3291130065917969, Accuracy: 89.14166259765625%\n",
            "Iteration: 2000, Loss: 0.18008233606815338, Accuracy: 90.75833129882812%\n",
            "Iteration: 2500, Loss: 0.20080791413784027, Accuracy: 91.29999542236328%\n",
            "Iteration: 3000, Loss: 0.1037425547838211, Accuracy: 90.3499984741211%\n",
            "Iteration: 3500, Loss: 0.09745321422815323, Accuracy: 90.66666412353516%\n",
            "Iteration: 4000, Loss: 0.19769905507564545, Accuracy: 90.56666564941406%\n",
            "Iteration: 4500, Loss: 0.13788123428821564, Accuracy: 90.11666870117188%\n",
            "Iteration: 5000, Loss: 0.2568441331386566, Accuracy: 90.125%\n",
            "Iteration: 5500, Loss: 0.03657910227775574, Accuracy: 90.53333282470703%\n",
            "Iteration: 6000, Loss: 0.1278616189956665, Accuracy: 90.74166870117188%\n",
            "Iteration: 6500, Loss: 0.1916695535182953, Accuracy: 90.26666259765625%\n",
            "Iteration: 7000, Loss: 0.033521637320518494, Accuracy: 91.25%\n",
            "Iteration: 7500, Loss: 0.16883820295333862, Accuracy: 90.7249984741211%\n",
            "Iteration: 8000, Loss: 0.20113803446292877, Accuracy: 90.5250015258789%\n",
            "Iteration: 8500, Loss: 0.058471422642469406, Accuracy: 90.69166564941406%\n",
            "Iteration: 9000, Loss: 0.05896969139575958, Accuracy: 89.88333129882812%\n",
            "Iteration: 9500, Loss: 0.03815896064043045, Accuracy: 90.56666564941406%\n",
            "Iteration: 10000, Loss: 0.034433528780937195, Accuracy: 90.51666259765625%\n",
            "Iteration: 10500, Loss: 0.005642903968691826, Accuracy: 91.07499694824219%\n",
            "Iteration: 11000, Loss: 0.002582559362053871, Accuracy: 91.31666564941406%\n",
            "Iteration: 11500, Loss: 0.010201048105955124, Accuracy: 91.29166412353516%\n",
            "Iteration: 12000, Loss: 0.018217939883470535, Accuracy: 91.13333129882812%\n"
          ]
        }
      ],
      "source": [
        "count=0\n",
        "predictions_list = []\n",
        "labels_list = []\n",
        "loss_list = []\n",
        "iteration_list = []\n",
        "accuracy_list = []\n",
        "best_model=0\n",
        "best_accuracy=100000\n",
        "for epoch in range(num_epochs):\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        train = Variable(images.view(100, 1, 28, 28))\n",
        "        labels = Variable(labels)\n",
        "\n",
        "        outputs = model(train)\n",
        "        loss = error(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        count += 1\n",
        "\n",
        "    # Testing the model\n",
        "\n",
        "        if not (count % 50):    # It's same as \"if count % 50 == 0\"\n",
        "            total = 0\n",
        "            correct = 0\n",
        "\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                labels_list.append(labels)\n",
        "\n",
        "                test = Variable(images.view(100, 1, 28, 28))\n",
        "\n",
        "                outputs = model(test)\n",
        "\n",
        "                predictions = torch.max(outputs, 1)[1].to(device)\n",
        "                predictions_list.append(predictions)\n",
        "                correct += (predictions == labels).sum()\n",
        "\n",
        "                total += len(labels)\n",
        "\n",
        "            accuracy = correct * 100 / total\n",
        "            loss_list.append(loss.data)\n",
        "            iteration_list.append(count)\n",
        "            accuracy_list.append(accuracy)\n",
        "            if(accuracy<best_accuracy):\n",
        "              best_accuracy=accuracy\n",
        "              best_model=model\n",
        "\n",
        "        if not (count % 500):\n",
        "            print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2tguH-JAHsR",
        "outputId": "e5ef684c-e9cc-4b33-f697-10db8806625b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(91.6364, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    labels_list.append(labels)\n",
        "\n",
        "    test = Variable(images.view(100, 1, 28, 28))\n",
        "\n",
        "    outputs = best_model(test)\n",
        "\n",
        "    predictions = torch.max(outputs, 1)[1].to(device)\n",
        "    predictions_list.append(predictions)\n",
        "    correct += (predictions == labels).sum()\n",
        "\n",
        "    total += len(labels)\n",
        "\n",
        "accuracy = correct * 100 / total;\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rezultate: Test - 92.05"
      ],
      "metadata": {
        "id": "yGETNk5t5kBK"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMC6FcHthBZdYWTF+5GUc16",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}